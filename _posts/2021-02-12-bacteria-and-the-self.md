---
title: "Bacteria, the self, and erasure of identity of its parts"
date: 2021-02-08
---

From bacteria to societies, is the erasure of one level of self the construction of the next? Thoughts on [Sean Carroll and Michael Levin's conversation](https://www.preposterousuniverse.com/podcast/2021/02/01/132-michael-levin-on-growth-form-information-and-the-self/).

Let me start by saying that the podcast contains a lot of great moments, and that I'll be zooming in on a precise one (timestamp 58:10), paraphrasing a bit:
> SC: At what point to a bunch of [cells] constitute an organism? At what point are they a "self"?  
> ML: There's two aspects; one is how cells come into being, all cognitive agents are made of parts, there's no such thing as this monadic cognitive thing that's not divisible, we are a bag of cells, the question isn't "can cells have goals?" that question has been settled, the only remain question is the scale. How do you scale up from a collection of competent agents to some sort of unified single agent that has a coherent integrated self?   

Michael Levin then goes on, he has model of this which has to do with proto-synapses, and explains a bit how they work. 

> ML: If you imagine two cells coming together and using [these proto-synapses], both cells get access to each other's internal millieu, this means that things that happen to one of the cells very rapidly propagate to the other cell, and all the meta-data as far as who the originator of that information is is stripped. So if something happens to cell A, [like a calcium flux], then all that cell B sees is this flux, is doesn't know whether what triggered it happen to it or to its partner.

That is unlike other stimuli, where the cells know that they are coming "from the environment" (e.g. other cells)

> ML: This has a couple of really critical implications, first, it makes lying or cheating almost impossible, because anything you do to your neighbour is immediately gonna come back to you. [..] It becomes difficult to maintain ownership of individual thought. If you have a [chemical] track record of what happened to you, you can no longer tell which are true memories that you accumulated, and which are false memories that are incepted in your cognitive structure by the fact that they floated in from your neighbour. It's like an amazing form of telepathy, it merges the mind of the two cells into a group agent where they cannot tell what belongs to what, and, I would claim, that is the origin of a simple compound self.

He then goes on to talk about a modified repeated prisonner's dilemma where on of the possible actions is "merge". Once merged, the only "rational" action becomes cooperation, because you don't want to defect against your<it>self</it>.

At some point, Sean Carroll points out that what he's describing sounds a lot like The Borg (from Star Trek), who are a single minded swarm of cyborgs, and Michael Levin points out this is a fair analogy but that he's not big on collectivist things. In that view of the self, there is a trade off between individuals and the collective.

> When you do combine into this collective, there are some good things about it: you achieve higher computational capacity, cooperation goes through the roof, all of that, but of course the goal of the collective agent might have absolutely nothing to do with the goals of individuals, [like our skin shedding].

Hmm. This combination isn't a choice, really, or rather it's a choice on perspective. We can choose to view our societies as big Selves. He goes on:

> We need to come up with optimal ways to enhance the benefits of this kind of cooperativity, but still rain the multi-scale nature of it. The key is you don't want to lose the agency of the pieces, you want to retain it while reaping the benefits of the larger scale features. And it's hard to say at this point how well **its gonna work** but I think that's a really important thing to work on in **the future**.

I think this is brilliant, and it's a very interesting perspective on multi-cellular organisms as well as societies, but I think he's missed an opportunity here. We can **already** try to understand multi-agent systems through this lense. The way this whole part of the conversation is framed, and perhaps this is due to the leading question on the Borg, is that we could use this to organize societies in the future. But we should probably actually use this insight now, to analyse societies that already exist.

What would such an analysis look like? Does it make sense to erase the self at the level of individual humans to see what emerges?

We already kind of do this, but I'd argue we don't always go the full way. Let's take the examples of **countries**, they
- are commonly thought of as entities
- are formed of many invididuals that cooperate
- have goals and desires (policies and trade agreements)
- sacrifice some individuals for the benefit of the collective (soldiers, and other dangerous "necessary" occupations)

I think we do a good job of anthropomorphising countries, but at the same time we fail to do so entirely. We know and conceive of countries and their goals as being orchestrated through democracy, politics, leaders, elected or not. But these mechanisms are not all powerful. Momentum, history, the lack of cooperation between citizens of a country (autoimmune reactions?), lots of things come together which sometimes force countries not to act in their apparent self-interest. More than that, these things are likely to push individuals to perform certain actions that are against their self-interest. 

Are countries then not some kind of Self which has goals and desires which transcend those of individuals?

Of course this is a leaky concept, leakier that that of a multicelluar organism. For example people travel and change countries all the time, in proportion more so than the number of cells (germs?) that leave our body to live a plentiful existence elsewhere. This is still a useful way of thinking.

When companies become so big that no one is really "in charge", and its only objective is profit, does it not become some kind of Self? Its goal for profit is often misaligned with the individual goals of its constituents (save for a few of course).

When some claim that [Earth is a superorganism](https://en.wikipedia.org/wiki/Superorganism), they are alluding to this concept. 

When anti-capitalists point out that capitalism is self-reproducing (pardon the lack of references, perhaps Mark Fisher?), they are alluding to this concept. Humans in our era tend to be organised under the Self of capitalism, and this Self tends to want to grow bigger and "eat" non-capitalist parts of the world, even though the individuals composing it don't necessarily want that (although sometimes they do).

Let's pause the socio-political commentary for now.

### Computation and the self

One of the interesting aspects of this cooperation that Michael Levin points out is that when multiple organisms come together, their computational capacity grows, sometimes superlinearly.

This neatly seems to come together for _artificial_ neural networks. Readers familiar with [scaling laws](https://arxiv.org/abs/2001.08361) and [neural complexity measures](https://arxiv.org/abs/1402.1869) might point out that networks neurons, at least artificial ones, can come together in suprising and exponentially powerful ways.


